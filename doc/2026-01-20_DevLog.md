# 2026-01-20 개발 로그 (네트워크 레이어 심층 분석 및 최적화 설계)

## 1. 네트워크 버퍼 구조 분석 완료
- **RecvBuffer 분석**: 지연 압축(Lazy Compaction) 방식의 선형 버퍼임을 확인.
- **Thread Safety**: IO 스레드 독점 모델을 통해 수신 버퍼의 Lock-Free 설계 의도 파악 및 주석 보강.
- **예외 처리**: 패킷 크기 제한(10KB) 및 버퍼 공간 부족 시 세션 종료 로직 검증.

## 2. 제로카피(Zero-Copy) 아키텍처 설계
- **기술 문서 작성**: `doc/ZeroCopy_Implementation_Plan.md` 생성.
- **Chained Block Buffer 검토**: 대규모 동시 접속(10,000+) 환경에서의 메모리 효율성과 하드웨어 캐시 미싱(Cache Miss) 간의 트레이드오프 분석.
- **하이브리드 전략**: 지연 시간을 위해 선형 버퍼를 유지하되, 참조 카운팅을 활용한 Zero-Copy 지향점 설정.

## 3. 네트워크 핫패스 병목 지점 식별
- **브로드캐스트 효율성**: 기존 N명 전송 시 N번의 할당/복사가 발생하는 문제 발견. (오늘의 우선순위 최적화 대상)
- **송신 선형화**: `Flush` 단계에서의 중복 메모리 복사(`_linearBuffer`) 확인.
- **메모리 풀 최적화**: 단일 4KB 블록 고정 할당으로 인한 캐시 오버헤드 식별.

## 4. 최적화 성과 (Benchmark 결과)
- **대상**: 1,000개 세션, 100회 반복 (총 100,000개 패킷)
- **결과**:
    - **Legacy**: 29ms
    - **Optimized**: **2ms** (약 14.5배 성능 향상)
- **함의**: 공유 메시지 구조와 지연 암호화의 조합이 로직 스레드의 오버헤드를 거의 완벽하게 제거함.

## 5. 향후 계획 (구체적 로드맵)

### [x] 디스패처 & 람다 최적화 (하이브리드 전략) - **완료**
- **실험 데이터**:
    - **Legacy (new/delete)**: 48ms
    - **Optimized (4KB Pool)**: 181ms (약 3.7배 성능 저하)
- **원인 분석**:
    - **내부 단편화**: 128바이트 내외의 람다 객체를 위해 4KB 블록을 할당하며 메모리 발자국이 거대해짐.
    - **캐시 미스**: 400MB 이상의 메모리 범위를 건드리며 L1/L2 캐시 효율이 급격히 저하됨.
    - **std::function 특성**: 람다 캡처 크기에 따라 내부적으로 추가 할당이 발생할 수 있어 고정 풀링의 이점이 희석됨.
- **최종 전략 (Hybrid Strategy)**:
    - **PacketMessage**: 4KB 풀링 유지 (대형 객체, 고정 크기, 단편화 방지)
    - **LambdaMessage**: 시스템 할당자(LFH) 사용 (소형 객체, 가변 크기, 캐시 효율 중시)
    - **Smart Notify**: 시스템 콜 오버헤드 제거 로직은 가성비가 매우 높으므로 유지.

### [ ] Asio Gather Write (Scatter-Gather IO) 적용
- **문제**: 현재는 여러 패킷을 보낼 때 하나의 `_linearBuffer`로 다시 복사하는 'Double Copy'가 발생함.
- **해결**: `boost::asio::async_write`에 패킷 리스트(`std::vector<const_buffer>`)를 그대로 넘겨서, OS 수준에서 여러 조각의 메모리를 모아서 한 번에 전송하도록 구현.
- **기대효과**: 송신 시 발생하는 모든 메모리 복사 비용을 0으로 제거 (최종 단계의 Zero-Copy 송신).

### [ ] 패킷 크기별 멀티 메모리 풀 (Sized Message Pool) 도입
- **문제**: 현재는 모든 패킷이 실제 크기와 무관하게 4KB 블록을 점유하여 메모리 파편화 및 CPU 캐시 낭비 발생.
- **해결**: 패킷 크기별로 풀을 세분화(예: Tiny-128B, Small-512B, Medium-2KB, Large-4KB)하여 메모리 밀도를 높임.
- **기대효과**: CPU 캐시 히트율 향상 및 수만 명 동시 접속 시 전체 메모리 사용량의 약 60~70% 절감 가능.

### [ ] 송신 큐(Send Queue) 경합성 개선
- **문제**: 송신 큐 삽입 시 여러 스레드가 몰릴 경우 Lock(또는 Atomic CAS) 경합 발생 가능성.
- **해결**: Thread-Local 송신 버퍼링 혹은 더 가벼운 락프리 큐 구조 도입 검토.
