# 제로카피(Zero-Copy) 아키텍처 구현 계획

> [!NOTE]  
> **상태: 보류 (Future Work)**  
> 2026-02-02: 현재 `MessagePool` 기반의 1-Copy 구조로도 충분한 성능을 확보하고 있습니다. 구조적 복잡도를 낮추기 위해 도입을 미루고 있으며, 추후 병목 발생 시 참조 카운팅 버퍼 구조로 전환할 계획입니다.

이 문서는 현재 프로젝트의 패킷 처리 구조(Double Copy)를 성능 극대화를 위한 제로카피(Zero-Copy) 구조로 전환하기 위한 기술적 가이드와 힌트를 담고 있습니다.

## 1. 현재 구조의 한계
- **데이터 복사 발생**: `RecvBuffer` -> `PacketMessage` 객체 생성 시 `memcpy` 발생.
- **객체 할당 오버헤드**: 패킷마다 `MessagePool`에서 메모리를 할당/해제함.
- **CPU 캐시 효율**: 데이터를 이동시킴으로써 하드웨어 레벨의 캐시 히트율이 저하될 가능성 존재.

## 2. 제로카피 설계 핵심 아이디어 (Hint)

### A. 참조 카운팅 버퍼 (Reference Counted Buffer)
- 패킷을 별도의 객체로 복사하는 대신, 수신 버퍼 자체를 참조 카운팅이 가능한 구조로 설계합니다.
- 로직 스레드가 패킷을 처리하는 동안에는 해당 버퍼 영역을 덮어쓰지 못하도록 `shared_ptr` 형식을 활용합니다.

### B. 스마트 뷰 (Smart Views)
- `std::span` (C++20) 또는 `std::string_view`를 사용하여 버퍼의 특정 위치와 길이를 가리키는 "View"를 로직 스레드에 전달합니다.
```cpp
// 예시: 패킷 메시지 구조체 대신 View를 전달
struct PacketView {
    std::shared_ptr<SharedBuffer> buffer; // 버퍼 생명주기 관리
    const uint8_t* data;                  // 실제 데이터 위치
    size_t length;                        // 패킷 길이
};
```

### C. 링버퍼(RingBuffer)와 세그먼트 관리
- 기존 선형 버퍼 대신 순수 링버퍼 구조를 채택합니다.
- **Write Cursor**: IO 스레드가 데이터를 채워 넣는 위치.
- **Read Cursor**: 로직 스레드가 데이터를 읽어가는 위치.
- **Logic Cursor (Safe Point)**: 로직 처리가 끝난 지점을 표시하여 IO 스레드가 다시 덮어쓸 수 있는 안전 구역을 계산합니다.

## 3. 구현 시 주의사항 및 해결 방안

### 1) 역전 현상 (Wrapping) 처리
- 링버퍼 끝부분에서 패킷이 잘리는 경우(Wrap-around), 데이터가 불연속적으로 배치됩니다.
- **해결책 (가상 메모리 트릭)**: 버퍼 사이즈를 두 배로 할당하고 가상 메모리 매핑을 통해 끝과 시작을 연결(Mirrored Buffer)하면 연속적인 `memcpy` 없이도 항상 선형적인 포인터 접근이 가능합니다.

### 2) 비동기 수명 주기 (Lifetime Management)
- IO 스레드는 데이터를 계속 받고 싶어 하지만, 로직 스레드가 패킷 처리를 늦게 하면 버퍼가 꽉 찹니다.
- **해결책**: 로직 스레드가 참조를 해제(Release)할 때만 Read 커서를 이동시키는 세밀한 동기화가 필요합니다.

### 3) 송신(Send) 제로카피 연동
- 수신뿐만 아니라 송신 시에도 `boost::asio::const_buffer`를 활용하여 직렬화된 데이터를 복사 없이 전송 큐에 직접 연결합니다.

## 4. 대규모 환경(10,000+)에서의 Chained Block Buffer 효율성
대규모 동시 접속 환경에서는 성능(Latency)만큼이나 **메모리 운용의 경제성**이 중요해집니다.

### A. 메모리 절약 (Economic Memory Usage)
- **고정 할당의 폐해**: 1만 명 유저에게 64KB씩 고정 할당 시 약 640MB가 즉각 점유됩니다.
- **Chained의 이득**: 접속 초기에는 4KB 블록 하나만 할당(총 40MB). 활동량(Fat Client vs Thin Client)에 따라 블록을 동적으로 증설하여 메모리 낭비를 원천 차단합니다.

### B. 페이지 단편화(Page Fragmentation) 해결
- 64KB 연속 메모리 확보보다 4KB 단위의 작은 조각들을 연결하는 것이 OS 수준의 메모리 할당 부담을 크게 줄여줍니다.

### C. Zero-Copy 참조 카운팅의 최적 단위
- 거대한 링버퍼 전체를 관리하는 것보다, 패킷이 담긴 특정 **'블록'** 단위로 참조 카운트를 매기는 것이 구현 상 더 명확하고 안전합니다.

## 5. 기대 효과
- **CPU 점유율 감소**: 대량 접속 시 `memcpy` 비용 제거로 시스템 안정성 향상.
- **메모리 효율 극대화**: 유저별 활동량에 따른 자원 재배치(Dynamic Scaling).
- **엔지니어링 완성도**: 고성능/고효율 네트워크 서버로서의 아키텍처적 우위 확보.

---

> [!NOTE]
> **웹 서버 vs MMORPG**: 
> Chained 구조는 데이터 크기 편차가 큰 웹 서버 환경에 매우 유리하지만, 극강의 Low-Latency가 필요한 MMORPG에서는 파싱 오버헤드를 고려해야 합니다. 따라서 **"선형 버퍼 기반의 빠른 파싱"**과 **"블록 기반의 유연한 관리"** 사이의 하이브리드 설계를 지향하는 것이 좋습니다.

> [!TIP]
> **성능 측정 우선**: 전환 전/후의 성능 차이를 측정하기 위해 `Google Benchmark` 등을 활용한 마이크로 벤치마킹 환경을 먼저 구축하는 것을 추천합니다.
